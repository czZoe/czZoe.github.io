@inproceedings{10.1145/3643834.3660683,
author = {Zhou, Chen and Yan, Zihan and Ram, Ashwin and Gu, Yue and Xiang, Yan and Liu, Can and Huang, Yun and Ooi, Wei Tsang and Zhao, Shengdong},
title = {GlassMail: Towards Personalised Wearable Assistant for On-the-Go Email Creation on Smart Glasses},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3660683},
doi = {10.1145/3643834.3660683},
abstract = {Optical See-through Head-Mounted Displays (OHMDs) offer new opportunities for completing complex information processing tasks on the go. We introduce GlassMail, a Large Language Models (LLMs)-based wearable assistant on OHMDs for mobile email creation. Our formative study identified two challenges of the LLM-based wearable email assistant: (i) achieving efficient and accurate understanding of user intentions, and (ii) ensuring effective information presentation for email processes. Through two empirical studies, we developed a "Single Turn with Optional Clarification " approach for accurate user intention recognition and a "Fade Context with Optional Audio " mode for effective email processing. An observation study then evaluated GlassMail ’s feasibility in composing formal and semi-formal emails, supporting the usefulness and effectiveness of GlassMail in simple scenarios and yielding insights into potential future improvements for complex scenarios. We further discuss the design implications for the future development of wearable AI-enabled assistants.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {372–390},
numpages = {19},
keywords = {Complex Information Processing, Heads-Up Computing, Large Language Model, Mobile Email Creation, Optical See-Through Head-Mounted Displays, Smart Glasses, Voice Assistant, Wearable LLM-based assistant},
location = {IT University of Copenhagen, Denmark},
series = {DIS '24}
}